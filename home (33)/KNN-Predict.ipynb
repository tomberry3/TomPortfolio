{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Predict Diabetes with K-NN\n",
                "\n",
                "### Objective: Predict whether a person will be diagnosed with diabetes or not\n",
                "\n",
                "- Dataset of 768 diagnosed people with or without diabetes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import necessary Libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.metrics import accuracy_score"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## K-NN Algorithm Explanation\n",
                "\n",
                " \u003ctable\u003e\n",
                "  \u003ctr\u003e\n",
                "    \u003ctd\u003e\n",
                "      \u003cimg src=\"KNN_graph1.png\" width=\"200\" /\u003e\n",
                "    \u003c/td\u003e\n",
                "        \u003ctd\u003e\n",
                "      \u003cimg src=\"KNN_graph3.png\" width=\"245\" /\u003e\n",
                "    \u003c/td\u003e\n",
                "    \u003ctd\u003e\n",
                "      \u003cimg src=\"KNN_graph2.png\" width=\"245\" /\u003e\n",
                "    \u003c/td\u003e\n",
                "  \u003c/tr\u003e\n",
                "\u003c/table\u003e\n",
                "\n",
                "- Group items by similar characteristics\n",
                "- K - the **hyperparameter**, the number of voting members\n",
                "- K (Number of Neighbors): The 'K' hyperparameter defines the number of nearest neighbors to consider when making predictions for a new data point. For example, if k=3, the algorithm will consider the three nearest neighbors to the query point and make a prediction based on the majority class among those three neighbors (for classification tasks). The choice of 'k' can significantly impact the algorithm's performance.\n",
                "\n",
                "Choosing the right value of 'k' is crucial because:\n",
                "\n",
                "- A small 'K' (e.g., k=1) can lead to noise sensitivity and overfitting. The algorithm might be highly influenced by outliers or noise in the data, leading to poor generalization to new data points.\n",
                "- A large 'K' (e.g., k=20) can lead to oversmoothing and underfitting. The algorithm may lose the ability to capture local patterns in the data, resulting in a more biased model."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Pre-processing\n",
                "\n",
                "- Values for 'Glucose' and 'Blood Pressure' etc. cannot be accepted as zeros (why?)\n",
                "- Replace these columns with the mean of the column\n",
                "- Replace with average since it is the most common for a person"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "768\n   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  \n"
                }
            ],
            "source": [
                "data = pd.read_csv(\"diabetes.csv\") #takes data from \"diabetes.csv\" file and puts it into the dataframe called \"data\"\n",
                "print(len(data)) #prints the number of rows in the data set\n",
                "print(data.head()) #prints the first few rows of data in the data set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "0      148.0\n1       85.0\n2      183.0\n3       89.0\n4      137.0\n       ...  \n763    101.0\n764    122.0\n765    121.0\n766    126.0\n767     93.0\nName: Glucose, Length: 768, dtype: float64\n155\n"
                }
            ],
            "source": [
                "# Listing the rows in which 0 is not an accepted value\n",
                "zero_not_accepted = ['Glucose', 'BloodPressure', 'SkinThickness','BMI', 'Insulin']\n",
                "\n",
                "# Iterates through the data and replace all the zeros with the mean of the data set\n",
                "for column in zero_not_accepted:\n",
                "    data[column] = data[column].replace(0, np.NaN) #replaces the zeros with \"NaN\"\n",
                "    mean = int(data[column].mean(skipna=True)) #determines the mean excluding the NaN's\n",
                "    data[column].fillna(mean, inplace=True) #replaces the NaN's with the mean\n",
                "\n",
                "print(data['Glucose'])\n",
                "print(mean) #prints the calculated mean"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = data.iloc[:, 0:8] # keeps all rows from 0-7\n",
                "y = data.iloc[:, 8] # keeps row 8\n",
                "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.2) # Split the dataset into train and test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Attribute scaling\n",
                "sc_x = StandardScaler()# sets all data between -1 and 1\n",
                "x_train = sc_x.fit_transform(x_train) #fits the scaler to the training features and transforms them\n",
                "x_test = sc_x.transform(x_test) #transforms the testing features using the scaling parameters learnt from the training data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Determining the model variables\n",
                "\n",
                "- The hyperparameter K should be an odd number (why?)\n",
                "- Use the square root of the length of the y_test set to pick K\n",
                "- p is the 'diabetic or not'\n",
                "- Euclidean is the method of measuring the distance between neighbors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "154\n"
                },
                {
                    "data": {
                        "text/plain": "12.409673645990857"
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Determine the K value (hyperparaneter)\n",
                "import math\n",
                "print(len(y_test)) #prints the length of the y_test dataset\n",
                "math.sqrt(len(y_test)) #calculates the Square root value of the length of the y_test dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cstyle\u003e#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}\u003c/style\u003e\u003cdiv id=\"sk-container-id-4\" class=\"sk-top-container\"\u003e\u003cdiv class=\"sk-text-repr-fallback\"\u003e\u003cpre\u003eKNeighborsClassifier(metric=\u0026#x27;euclidean\u0026#x27;, n_neighbors=11)\u003c/pre\u003e\u003cb\u003eIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. \u003cbr /\u003eOn GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u003c/b\u003e\u003c/div\u003e\u003cdiv class=\"sk-container\" hidden\u003e\u003cdiv class=\"sk-item\"\u003e\u003cdiv class=\"sk-estimator sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked\u003e\u003clabel for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\"\u003eKNeighborsClassifier\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content\"\u003e\u003cpre\u003eKNeighborsClassifier(metric=\u0026#x27;euclidean\u0026#x27;, n_neighbors=11)\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
                        "text/plain": "KNeighborsClassifier(metric='euclidean', n_neighbors=11)"
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Initialises the KNN classifier accompanied by specific parameters\n",
                "classifier = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')\n",
                "classifier.fit(x_train, y_train) #fits the classifier to the training model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "y_pred = classifier.predict(x_test) # Predict the test results using the trained classifier\n",
                "y_pred"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### The Confusion Matrix Analysis Tool\n",
                "\n",
                "In machine learning, the confusion matrix is a table that is used to evaluate the performance of a classification model, such as a K-Nearest Neighbors (KNN) model. It provides a comprehensive summary of the predictions made by the model on a test dataset, compared to the actual ground truth labels. The confusion matrix has four important metrics: True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
                "\n",
                "1. True Positives (TP): The number of instances that are correctly predicted as positive (belong to the positive class).\n",
                "\n",
                "2. False Positives (FP): The number of instances that are incorrectly predicted as positive but actually belong to the negative class.\n",
                "\n",
                "3. True Negatives (TN): The number of instances that are correctly predicted as negative (belong to the negative class).\n",
                "\n",
                "4. False Negatives (FN): The number of instances that are incorrectly predicted as negative but actually belong to the positive class.\n",
                "\n",
                "\u003ctable\u003e\n",
                "    \u003ctr\u003e\n",
                "        \u003cth\u003eActual\u003c/th\u003e\n",
                "        \u003cth\u003ePredicted Positive\u003c/th\u003e\n",
                "        \u003cth\u003ePredicted Negative\u003c/th\u003e\n",
                "    \u003c/tr\u003e\n",
                "    \u003ctr\u003e\n",
                "        \u003ctd\u003eActual Positive \u003c/td\u003e\n",
                "        \u003ctd\u003eTP\u003c/td\u003e\n",
                "        \u003ctd\u003eFN\u003c/td\u003e\n",
                "    \u003c/tr\u003e\n",
                "    \u003ctr\u003e\n",
                "        \u003ctd\u003eActual Negative \u003c/td\u003e\n",
                "        \u003ctd\u003eFP\u003c/td\u003e\n",
                "        \u003ctd\u003eTN\u003c/td\u003e\n",
                "    \u003c/tr\u003e\n",
                "\u003c/table\u003e\n",
                "\n",
                "Here's how to interpret the confusion matrix:\n",
                "\n",
                "1. TP (True Positives): The model correctly predicted instances that belong to the positive class.\n",
                "\n",
                "2. FN (False Negatives): The model incorrectly predicted instances as negative when they actually belong to the positive class.\n",
                "\n",
                "3. FP (False Positives): The model incorrectly predicted instances as positive when they actually belong to the negative class.\n",
                "\n",
                "4. TN (True Negatives): The model correctly predicted instances that belong to the negative class.\n",
                "\n",
                "Using these values, we can compute various evaluation metrics, such as **accuracy**, precision, recall (sensitivity), specificity, and **F1-score**, which help us assess the performance of the KNN model on the test data.\n",
                "\n",
                "- Accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
                "- Precision = TP / (TP + FP)\n",
                "- Recall (Sensitivity) = TP / (TP + FN)\n",
                "- Specificity = TN / (TN + FP)\n",
                "- F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
                "\n",
                "A good KNN model will have a high accuracy, precision, recall, specificity, and F1-Score, indicating that it is making correct predictions for both positive and negative classes.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "[[94 13]\n [15 32]]\n0.6956521739130436\n"
                }
            ],
            "source": [
                "# Evaluate the model\n",
                "cm = confusion_matrix(y_test, y_pred)#calculates the confusion matrix depending on the labels \"y_test\", and \"y_pred\"\n",
                "print(cm) #prints the confusion matrix\n",
                "print(f1_score(y_test, y_pred)) #calculates the F1 score"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### To interpret the results in the confusion matrix \n",
                "[[94, 13], \n",
                "[15, 32]]\n",
                "\n",
                "```\n",
                "             Predicted Positive    Predicted Negative\n",
                "Actual Positive        94                13\n",
                "Actual Negative        15                32\n",
                "```\n",
                "\n",
                "Here's how to interpret the values:\n",
                "\n",
                "1. True Positives (TP): The number of instances that are correctly predicted as positive. In this case, there are 94 true positives, meaning 94 instances were correctly classified as positive (belong to the positive class).\n",
                "\n",
                "2. False Positives (FP): The number of instances that are incorrectly predicted as positive but actually belong to the negative class. In this case, there are 13 false positives, meaning 13 instances were incorrectly classified as positive when they actually belong to the negative class.\n",
                "\n",
                "3. True Negatives (TN): The number of instances that are correctly predicted as negative. In this case, there are 32 true negatives, meaning 32 instances were correctly classified as negative (belong to the negative class).\n",
                "\n",
                "4. False Negatives (FN): The number of instances that are incorrectly predicted as negative but actually belong to the positive class. In this case, there are 15 false negatives, meaning 15 instances were incorrectly classified as negative when they actually belong to the positive class.\n",
                "\n",
                "Based on these values, we can calculate various evaluation metrics to assess the performance of the classification model:\n",
                "\n",
                "1. Accuracy: It is the overall correctness of the model's predictions and is calculated as (TP + TN) / (TP + FP + TN + FN). In this case, accuracy = (94 + 32) / (94 + 13 + 15 + 32) ≈ 0.8095 or 80.95%.\n",
                "\n",
                "2. Precision: It measures the accuracy of the positive predictions and is calculated as TP / (TP + FP). In this case, precision = 94 / (94 + 13) ≈ 0.8785 or 87.85%.\n",
                "\n",
                "3. Recall (Sensitivity): It measures the ability of the model to correctly identify positive instances and is calculated as TP / (TP + FN). In this case, recall = 94 / (94 + 15) ≈ 0.8621 or 86.21%.\n",
                "\n",
                "4. F1-Score: It is the harmonic mean of precision and recall and is given by 2 * (Precision * Recall) / (Precision + Recall). In this case, F1-Score = 2 * (0.8785 * 0.8621) / (0.8785 + 0.8621) ≈ 0.8702 or 87.02%.\n",
                "\n",
                "Our model has a relatively good accuracy, precision, recall, and F1-Score, indicating it performs reasonably well on the given test dataset. However, further analysis and comparison with other models may be necessary for a comprehensive evaluation."
            ]
        }
    ]
}
